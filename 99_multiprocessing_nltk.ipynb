{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "[nltk_data] Downloading package punkt to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package brown to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Process, Manager\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('brown')\n",
    "import pickle as pkl\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "import multiprocessing as mp,os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(temp_chunk):\n",
    "    data_logs = [' '.join(result) for result in temp_chunk]\n",
    "    print(data_logs)\n",
    "    return data_logs\n",
    "\n",
    "def divide_chunks(l, n): \n",
    "    for i in range(0, len(l), n):  \n",
    "        yield process(l[i:i + n])\n",
    "\n",
    "def process_wrapper(chunkStart, chunkSize,abs_file_path):\n",
    "    with open(abs_file_path) as f:\n",
    "        temp_words_l2=[]\n",
    "        temp_words_l1=[]\n",
    "        result_l2 = []\n",
    "        f.seek(chunkStart)\n",
    "        lines = f.read(chunkSize).splitlines()\n",
    "        for line in lines:\n",
    "            result_l2 = process(line,temp_words_l1)\n",
    "        temp_words_l2.extend(result_l2)\n",
    "        return temp_words_l2\n",
    "\n",
    "    \n",
    "def chunkify(fname,size=4096):\n",
    "    fileEnd = os.path.getsize(fname)\n",
    "    with open(fname,'rb') as f:\n",
    "        chunkEnd = f.tell()\n",
    "        while True:\n",
    "            chunkStart = chunkEnd\n",
    "            f.seek(size,1)\n",
    "            f.readline()\n",
    "            chunkEnd = f.tell()\n",
    "            yield chunkStart, chunkEnd - chunkStart\n",
    "            if chunkEnd > fileEnd:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "============== RESULTS =============\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    cores=90\n",
    "    file=\"/home/ubuntu/MSDA_Cox/results_test.pkl\"\n",
    "    object_file = pkl.load(open(\"results_test.pkl\",'rb'))\n",
    "    chunk_size = 4096\n",
    "    #pool = mp.Pool(cores)\n",
    "    with Manager() as manager:\n",
    "        L = manager.list()  # <-- can be shared between processes.\n",
    "        processes = []\n",
    "            #p = Process(target=dothing, args=(L,i))  # Passing the list\n",
    "            #p = pool.apply_async(process_wrapper,(chunkStart,chunkSize,abs_file_path))\n",
    "        p = Process(target=divide_chunks, args=(object_file,chunk_size)) \n",
    "        p.start()\n",
    "        processes.append(p)\n",
    "        for p in processes:\n",
    "            p.join()\n",
    "        print(L)\n",
    "\n",
    "print(\"============== RESULTS =============\")\n",
    "results=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_file = p.load(open(\"results_rev1.pkl\",'rb'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(object_file[0])\n",
    "for log in object_file[0:10]:\n",
    "    joined = [' '.join(word) for word in log]\n",
    "print(joined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for item in object_file:\n",
    "    results.append(item)\n",
    "\n",
    "data_logs = [' '.join(result) for result in results[-100000:]]\n",
    "\n",
    "data_logs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dothing(L, i):  # the managed list `L` passed explicitly.\n",
    "    L.append(\"anything\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    with Manager() as manager:\n",
    "        L = manager.list()  # <-- can be shared between processes.\n",
    "        processes = []\n",
    "\n",
    "        p = Process(target=dothing, args=(L,i))  # Passing the list\n",
    "        p.start()\n",
    "        processes.append(p)\n",
    "        for p in processes:\n",
    "            p.join()\n",
    "        print(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
